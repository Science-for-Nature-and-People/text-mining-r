---
Gittitle: "Text Mining with TM and Quanteda packages"
author: "Gabriel Antunes Daldegan, NCEAS, UCSB"
date: "5/10/2017"
output: html_document
---
# Using TM and Quanteda packages to mine keywords from a set of scientific papers

Install packages specialized in text mining routines

```{r echo=FALSE,warning=F,message=F}
# install.packages('tm') # installs 'tm-Text Mining' package: https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
# install.packages('quanteda') # installs 'quanteda' package: https://github.com/kbenoit/quanteda
```

Load packages

```{r, message = FALSE}
library('tm') # loads Text Mining package
library('quanteda') # loads Quanteda package
```

## Using TM package to read in pdf files

In this section, we ingest the papers to be mined into R. This step converts the PDFs into the VCorpus object, which is the object class from the TextMining (TM) package that store the text in memory. We followed the tuturial found here: http://data.library.virginia.edu/reading-pdf-files-into-r-for-text-mining/.

TM has a readPDF function, but it requires an external engine to effectively transfomr PDF format inot text. We opted for the XPDF engine, available at http://www.foolabs.com/xpdf/download.html. As we are working on Mac OSX, it required XCode to be installed in the machine for compilation purposes. We followed these steps to install XPDF: https://apple.stackexchange.com/questions/171003/install-xpdf-in-mac-os. In case it is needed to install XPDF on a Windows maching, here is a link on how to proceed: https://mbnuijten.files.wordpress.com/2013/08/manualinstallationxpdflakens.pdf

```{r}
# list of pdf files we want to mine
pdf <- list.files(pattern= 'pdf$') 

# created a function to read PDF file into R as text. readPDF has two control parameters: info, which passes parameters to pdfinfo.exe, and text, which passes parameters to pdftotext.exe. Here only the text parameter is passed, '-layout', telling pdftotext.exe to maintain the original physical layout of the text
pdfRead <- readPDF(control = list(text= '-layout'))

# applies the function to read in pdf files and coerce them to a TM's VCORPUS
papers <- Corpus(URISource(pdf), readerControl = list(reader=pdfRead)) 
```

## Text mining with Quanteda package

Now, we have a VCorpus object storing the papers we want to explore. We will take advantage of text mining functions from Quanteda.

First, let us convert the VCorpus from TM to a Quanteda's Corpus. We opted to follow this workflow for simplicity, once we already using TM/XPDF to read in pdf files
```{r}
# coerces the VCorpus object created using TM to a Quanteda Corpus
myCorpus <- corpus(papers)

# visualize corpus structure and contents
# summary(myCorpus) 
```

We can add metadata to the Corpus object, for instance, saying that the texts are written in English.

```{r}
# add metadata to files, in this case that they are written in english
metadoc(myCorpus, 'language') <- "english" 

# visualize corpus structure and contents, now with added metadata
summary(myCorpus, showmeta = T)
```

Now we build a Document-Feature Matrix (DFM). More information about DFM can be found on Quanteda's vignette: http://quanteda.io/articles/quickstart.html

```{r}
# builds the 'Document-Feature Matrix' (dfm), which is the base object to further explore the texts
myDFM <- dfm(myCorpus,tolower = TRUE, stem = F, remove= c('et', 'al',stopwords('english')), remove_punct = TRUE, remove_numbers=TRUE)

# returns the top frequent words
topfeatures(myDFM, 100) 
```

and we can plot a word cloud to visualize the most used words.

```{r}
# set the seed for wordcloud
set.seed(10)

# plots wordcloud
textplot_wordcloud(myDFM, min.freq=20, random.order=F, rot.per=.10, colors=RColorBrewer::brewer.pal(8,'Dark2')) 
```

A powerful feature of Quanteda is to be able to pass a dictionary of keywords we want to search within the texts

```{r}
# builds the dictionary of keywords
myDict <- dictionary(list(vegetation=c('forest', 'vegetation', 'trees', 'landscape'), fire= c('fire','burn', 'burned', 'burnt'), climate =c('dry', 'wet', 'cool','cold', 'warm', 'hot')))

# applies the dictonary as an argument when building the document-feature matrix 
byMyDict <- dfm(myCorpus, dictionary = myDict) 

# check the object retuned after applying dictionary
byMyDict 
```

We can also pass the dictionary to the 'locate keywords-in-context'function - kwic(), which will look for the keywords and bring the context in which they appear in the text

```{r}
# search for the keywords in the dictionary, returning the 3 words that are before and after the keyword
KeyWordsInContext <- kwic(myCorpus, myDict, window = 3) 

# check the keywords found and their context
head(KeyWordsInContext)
```
